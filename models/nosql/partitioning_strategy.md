# StratÃ©gie de Partitionnement - Azure Cosmos DB

## Principes Fondamentaux

### RÃ¨gles d'Or du Partitionnement Cosmos DB

1. **Haute cardinalitÃ©** : Minimum 1000+ valeurs uniques
2. **Distribution uniforme** : Ã‰viter les "hot partitions" (> 20% du trafic)
3. **RequÃªtes efficaces** : 80% des requÃªtes incluent la partition key
4. **ImmuabilitÃ©** : La partition key ne peut pas Ãªtre modifiÃ©e aprÃ¨s crÃ©ation

**Sources :**
- [Cosmos DB Partitioning Best Practices](https://learn.microsoft.com/en-us/azure/cosmos-db/partitioning-overview)
- [Choosing a Partition Key](https://learn.microsoft.com/en-us/azure/cosmos-db/partition-data)

---

## Analyse par Collection

### 1. Collection `api_logs`

#### Partition Key : `/merchant_id`

**Justification :**
- **CardinalitÃ© Ã©levÃ©e** : ~500,000 marchands actifs (source : Stripe Atlas)
- **Pattern d'accÃ¨s** : 95% des requÃªtes filtrent par marchand
- **Distribution** : Loi de Pareto (20% marchands = 80% volume) mais acceptable

**MÃ©triques de Performance :**
```
RequÃªtes typiques :
- "Logs des 24h pour merchant X" â†’ 1 partition (optimal)
- "Top 10 erreurs 500 tous marchands" â†’ Fan-out (acceptable, requÃªte rare)

Taille partition (P99) : ~3.6GB
- Top merchant : 20,000 requÃªtes/jour Ã— 2KB Ã— 90 jours = 3.6GB
- Limite Cosmos DB : 50GB/partition â†’ Marge de 13x 
```

**Alternative Ã©valuÃ©e et rejetÃ©e :**
- `/timestamp` : CrÃ©erait des hot partitions (toutes les Ã©critures rÃ©centes sur mÃªme partition)
- `/endpoint` : Faible cardinalitÃ© (~50 endpoints), dÃ©sÃ©quilibre majeur

---

### 2. Collection `user_sessions`

#### Partition Key : `/user_id`

**Justification :**
- **CardinalitÃ© trÃ¨s Ã©levÃ©e** : ~2,000,000 utilisateurs actifs
- **Isolation parfaite** : ZÃ©ro requÃªte cross-user (RGPD compliance)
- **Distribution** : TrÃ¨s uniforme (B2B SaaS pattern)

**MÃ©triques de Performance :**
```
RequÃªtes typiques :
- "Sessions actives user X" â†’ 1 partition (optimal)
- "DurÃ©e moyenne sessions globale" â†’ NÃ©cessite agrÃ©gation OLAP (pas Cosmos DB)

Taille partition (P99) : ~750KB
- User actif : 50 sessions/mois Ã— 5KB Ã— 30 jours TTL = 750KB
- Limite Cosmos DB : 50GB/partition â†’ Marge de 66,000x 
```

**Optimisation supplÃ©mentaire :**
- **Composite key envisagÃ©** : `/user_id` + `/session_start` â†’ RejetÃ© (over-engineering)
- Raison : TTL de 30 jours garde les partitions petites naturellement

---

### 3. Collection `fraud_features`

#### Partition Key : `/payment_id`

**Justification :**
- **CardinalitÃ© extrÃªme** : ~600,000,000 paiements sur 180 jours
- **AccÃ¨s transactionnel** : 100% des requÃªtes par payment_id (scoring temps rÃ©el)
- **Write-heavy** : 1 write par paiement, trÃ¨s peu de reads aprÃ¨s calcul

**MÃ©triques de Performance :**
```
RequÃªtes typiques :
- "Features pour payment X" â†’ 1 partition, < 5ms (critique)
- "RÃ©entraÃ®nement modÃ¨le ML" â†’ Export bulk vers Azure ML (pas via Cosmos DB)

Taille partition : 3KB fixe
- 1 document par payment_id (relation 1:1)
- Limite Cosmos DB : 50GB/partition â†’ N/A (1 doc/partition) 
```

**Trade-off assumÃ© :**
- **Contre** : Impossible de requÃªter "tous les paiements frauduleux" efficacement
- **Pour** : Latence ultra-faible (< 10ms) sur cas d'usage critique (scoring)
- **Solution** : RequÃªtes analytiques via Change Feed â†’ Synapse Analytics

---

### 4. Collection `webhook_events`

#### Partition Key : `/merchant_id`

**Justification :**
- **CardinalitÃ© Ã©levÃ©e** : ~500,000 marchands
- **Isolation retry logic** : Chaque marchand a sa propre file d'attente
- **Pattern FIFO** : Webhooks processÃ©s par marchand (Ã©vite race conditions)

**MÃ©triques de Performance :**
```
RequÃªtes typiques :
- "Webhooks failed pour merchant X" â†’ 1 partition (optimal)
- "Retry webhook Y" â†’ Update sur 1 partition (optimal)
- "Stats globales webhooks" â†’ AgrÃ©gation OLAP (pas Cosmos DB)

Taille partition (P99) : ~1.2GB
- Top merchant : 10,000 Ã©vÃ©nements/jour Ã— 4KB Ã— 60 jours = 2.4GB
- Limite Cosmos DB : 50GB/partition â†’ Marge de 20x 
```

**ğŸ”§ StratÃ©gie de retry :**
```javascript
// Exponential backoff calculÃ© via partition key
function calculateNextRetry(merchant_id, retry_count) {
  // Tous les retries d'un marchand restent dans mÃªme partition
  const baseDelay = 60; // 1 minute
  return baseDelay * Math.pow(2, retry_count); // 1min, 2min, 4min, 8min...
}
```

---

## Anti-Patterns Ã  Ã‰viter

### Anti-Pattern #1 : Partition Key de faible cardinalitÃ©
```json
// MAUVAIS : Seulement ~200 pays
"partitionKey": "/country"

// RÃ©sultat : Hot partition sur US (~40% du trafic Stripe)
```

### Anti-Pattern #2 : Partition Key temporelle
```json
// MAUVAIS : Toutes les Ã©critures rÃ©centes sur mÃªme partition
"partitionKey": "/date"

// RÃ©sultat : Throttling (429 errors) sur partition du jour courant
```

### Anti-Pattern #3 : Partition Key mutable
```json
// MAUVAIS : Le statut change souvent
"partitionKey": "/status"

// RÃ©sultat : Impossible de modifier (recrÃ©ation document nÃ©cessaire)
```

---

## Simulation de Charge

### Test de Stress : Black Friday Scenario

**HypothÃ¨ses :**
- Volume normal : 100M transactions/jour
- Peak Black Friday : 500M transactions/jour (5x)
- DurÃ©e peak : 6 heures

**Impact par collection :**

#### `api_logs` (criticalitÃ© : moyenne)
```
Normal : 10M API calls/jour = 115 RPS
Peak   : 50M API calls/6h   = 2,300 RPS

RU consumption : 2,300 RPS Ã— 10 RU/write = 23,000 RU/s
Provisioned    : 50,000 RU/s (autoscale)
Headroom       : 117% 
```

#### `fraud_features` (criticalitÃ© : HAUTE)
```
Normal : 100M paiements/jour = 1,157 RPS
Peak   : 500M paiements/6h   = 23,148 RPS

RU consumption : 23,148 RPS Ã— 15 RU/write = 347,220 RU/s
Provisioned    : 30,000 RU/s (autoscale)
INSUFFISANT â†’ Augmenter Ã  400,000 RU/s pour Black Friday
```

**Estimation coÃ»t Black Friday :**
```
400,000 RU/s Ã— 6 heures Ã— $0.008/RU-hour = $19,200
vs Perte d'un paiement frauduleux = $50,000 moyenne

ROI : Positif 
```

---

## StratÃ©gies de Repartitionnement

### ScÃ©nario : Croissance dÃ©sÃ©quilibrÃ©e d'un marchand

**ProblÃ¨me :**
```
Marchand "MegaCorp" dÃ©passe 40GB sur partition
â†’ Approche limite de 50GB
â†’ Risque de throttling
```

**Solution 1 : Hierarchical Partition Key (Cosmos DB v3+)**
```json
{
  "partitionKey": ["/merchant_id", "/date"],
  "data": {
    "merchant_id": "acct_megacorp",
    "date": "2025-10-19"
  }
}
```
- âœ… Distribue charge sur plusieurs partitions physiques
- âŒ Complexifie requÃªtes (doivent inclure date)

**Solution 2 : Sharding applicatif**
```javascript
// Hash merchant_id vers N shards
function getShardedPartitionKey(merchant_id) {
  const hash = murmurhash(merchant_id);
  const shard = hash % 10; // 10 shards
  return `${merchant_id}_shard${shard}`;
}
```
- âœ… Transparent pour Cosmos DB
- âŒ Logique custom dans application

**Recommandation Stripe :**
- < 1TB total : Aucune action nÃ©cessaire
- 1-10TB : Monitorer top 10 marchands, prÃ©parer Solution 1
- \> 10TB : ImplÃ©menter Solution 2 + Consider Azure Synapse for analytics

---

## Checklist de Validation

### Avant DÃ©ploiement Production

- [ ] **CardinalitÃ©** : Partition key a > 10,000 valeurs uniques
- [ ] **Distribution** : Aucune partition > 10% du trafic total
- [ ] **RequÃªtes** : 80%+ incluent partition key dans WHERE clause
- [ ] **Sizing** : P99 partition < 20GB (marge de 2.5x vs limite)
- [ ] **Monitoring** : Alertes configurÃ©es sur PartitionKeyRangeStatistics
- [ ] **Load testing** : TestÃ© Ã  3x la charge anticipÃ©e
- [ ] **TTL configurÃ©** : Ã‰vite croissance infinie des partitions
- [ ] **Backup strategy** : Continuous backup activÃ©
- [ ] **Failover** : Multi-rÃ©gion testÃ©e en conditions rÃ©elles
- [ ] **Cost analysis** : Budget RU/s validÃ© avec FinOps

---

## RÃ©fÃ©rences

- [Azure Cosmos DB Capacity Calculator](https://cosmos.azure.com/capacitycalculator/)
- [Partition Key Design Patterns](https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/modeling-data)
- [Stripe Engineering: Scaling to Billions](https://stripe.com/blog/scaling-api)
- [Avoiding Hot Partitions](https://learn.microsoft.com/en-us/azure/cosmos-db/sql/troubleshoot-request-rate-too-large)